function ex2()
  %% Online Learning Machine Class - Упражнение 2: Логистическая регрессия
  %
  %  Инструкции
  % ------------
  %
  % Этот файл содержит код, который поможет вам начать работу с логистикой
  % регрессии упражнений. Вам нужно будет выполнить следующие функции
  % в этом упражнении:
  %
  % sigmoid.m
  % costFunction.m
  % predict.m
  % costFunctionReg.m
  %
  % Для этого упражнения вам не нужно изменять код в этом файле,
  % или любые другие файлы, кроме упомянутых выше.
  %

  %% Initialization
  clear ; close all; clc

  %% Загрузить данные
  %  Первые два столбца содержат результаты экзамена и третий столбец
  %  содержит метку.

  data = load('ex2data1.txt');
  X = data(:, [1, 2]); 
  y = data(:, 3);



%% ==================== Part 1: Plotting ====================
% Мы начинаем упражнение, сначала нанося данные, чтобы понять
% проблема, с которой мы работаем

  fprintf(['Отображение данных с помощью `+`, указывающего (y = 1) примеров,'...
    'и `o`, указывающего (y = 0) примеров..\n']);

  plotData(X, y);

  % Put some labels 
  hold on;
  % Labels and Legend
  xlabel('Exam 1 score')
  ylabel('Exam 2 score')

  % Specified in plot order
  legend('Admitted', 'Not admitted')
  hold off;

  fprintf('\nПрограмма приостановлена. Нажмите ввод, чтобы продолжить.\n'); 
  pause;


%% ============ Part 2: Compute Cost and Gradient ============
% В этой части упражнения вы будете реализовывать стоимость и градиент
% для логистической регрессии. Вам нужно завершить код в
% costFunction.m

  %  Setup the data matrix appropriately, and add ones for the intercept term
  [m, n] = size(X);

  % Add intercept term to x and X_test
  X = [ones(m, 1) X];

  % Initialize fitting parameters
  initial_theta = zeros(n + 1, 1);

  % Вычислить и отобразить начальные затраты и градиент
  [cost, grad] = costFunction(initial_theta, X, y);

  fprintf('\nЗатраты при нулевой theta: %f == 0.693 (Ожидаемые затраты)\n', cost);
  fprintf('Градиент при нулевой theta: [%f; %f; %f] == [-0.1000; -12.0092; -11.2628] (Ожидаемые градиенты)\n',grad);
   
   
  % Вычислить и отобразить стоимость и градиента с ненулевым theta
  test_theta = [-24; 0.2; 0.2];
  [cost, grad] = costFunction(test_theta, X, y);

  fprintf('\nЗатраты при тестовой theta: %f == 0.218 (Ожидаемый затраты)\n', cost);
  fprintf('Градиент при тестовой theta: [%f; %f; %f] == [0.043; 2.566; 2.647] (Ожидаемые градиенты)\n',grad);
   
  fprintf('\nПрограмма приостановлена. Нажмите ввод, чтобы продолжить.\n\n');
  pause;


%% ============= Part 3: Optimizing using fminunc  =============
% В этом упражнении вы будете использовать встроенную функцию (fminunc), чтобы найти
% оптимальных параметров тета .

% В предыдущем задании вы нашли оптимальные параметры линейного
% Модель грессии путем реализации градиентного спуска. Вы написали функцию стоимости
% и вычислил его градиент, затем сделал шаг градиентного спуска соответственно.
% На этот раз вместо шагов градиентного спуска вы будете использовать Octave / -
% Встроенная функция MATLAB называется fminunc
% Для логистической регрессии, вы хотите
% оптимизировать функцию стоимости J () с параметрами.
% Конкретно, вы собираетесь использовать fminunc для поиска лучших параметров
% для функции стоимости логистической регрессии, учитывая фиксированный набор данных (из X и Y значения)

  %  Set options for fminunc
  %  GradObj Функция возвращает как стоимость, так и градиент
  % Чтобы указать фактическую функцию, которую мы минимизируем, мы используем  @(t) short-hand
  options = optimset('GradObj', 'on', 'MaxIter', 400);
 
  % Запустите fminunc для получения оптимального тета
  % Эта функция будет возвращать тета и стоимость 
  [theta, cost] = fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);

  % Обратите внимание, что при использовании fminunc вам не нужно было писать циклы
  % или установить скорость обучения, как вы это делали для градиентного спуска.
  % После завершения fminunc  вызовет вашу функцию costFunction используя оптимальные параметры!

  % Print theta to screen
  fprintf('Затраты theta с помощью fminunc: %f == 0.203 (Ожидаемые затраты)\n', cost);
  
  fprintf('theta: [%f; %f; %f] == [-25.161; 0.206; 0.201] (Ожидаемая theta)',theta);
  

  % Plot Boundary
  plotDecisionBoundary(theta, X, y);

  % Put some labels 
  hold on;
  % Labels and Legend
  xlabel('Exam 1 score')
  ylabel('Exam 2 score')

  % Specified in plot order
  legend('Admitted', 'Not admitted')
  hold off;

  fprintf('\nПрограмма приостановлена. Нажмите ввод, чтобы продолжить.\n');
  pause;

  %% ============== Part 4: Predict and Accuracies ==============
  % После изучения параметров, вы хотите использовать его для прогнозирования результатов
  % на невидимых данных. 
  % В этой части вы будете использовать модель логистической регрессии
  %, чтобы предсказать вероятность того, что студент с результатом 45 на экзамене 1 и
  % 85 баллов на экзамене 2 будут приняты.
  %
  % Кроме того, вы будете вычислять точность обучения и набора тестов
  % наша модель.
  %
  % Ваша задача завершить код в predict.m

  % Прогноз вероятности для студента с баллом 45 на экзамене 1
  % и оценка 85 на экзамене 2
  input_exam_1 =45;%70;%45;
  input_exam_2 = 85;%10;%85;
  prob = sigmoid([1 input_exam_1 input_exam_2] * theta);
  
  
  fprintf(['\nДля студента с баллами за первый экзамен %d и %d за второй мы прогнозируем поступление ' ...
           'с вероятностью %f == 0.775 +/- 0.002(Ожидаемое значение)\n\n'],input_exam_1, input_exam_2, prob );
   
    % Вычислите точность на нашем тренировочном наборе
  p = predict(theta, X);
  
  fprintf('Точность: %f == 89.0(Ожидаемая точность)\n\n', mean(double(p == y)) * 100);
  fprintf('\nПрограмма приостановлена. Нажмите ввод, чтобы продолжить.\n');
  pause;
 
endfunction



